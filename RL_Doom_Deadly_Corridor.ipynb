{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2d0882",
   "metadata": {},
   "source": [
    "# Setting Up VizDoom Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5890935-a340-4594-91b1-faf10017eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making an AI Model to play Doom using Reinforcement Learning\n"
     ]
    }
   ],
   "source": [
    "print(\"Making an AI Model to play Doom using Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff8ce04-0bfe-45f3-a091-92a9bdaefa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Vizdoom:\n",
    "# %pip install vizdoom #For VSCode\n",
    "# # OR\n",
    "# !pip install vizdoom #For Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308191ca-e4d4-4273-b61d-b3e4dede6add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git #For VSCode\n",
    "# # OR\n",
    "# !cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git #For Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8e0dc3-03b2-4420-8402-291dbb748cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26609d82-3284-4263-ad2f-d3400e5c8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame() # Creating game instance\n",
    "game.load_config('github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_1.cfg') # Loading the configs like Buttons, MoveSet(Going left or right etc), Bots config etc.\n",
    "game.init() # Initializing the Game/Staring the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88896ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   0.   0.  52.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(game.get_state().game_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "42bb576e-640f-42f1-b9c3-bde0b5c6a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.identity(7, dtype=np.uint8)\n",
    "print(actions)\n",
    "random.choice(actions)\n",
    "\n",
    "# [1 0 0 0 0 0 0] = MOVE_LEFT\n",
    "# [0 1 0 0 0 0 0] = MOVE_RIGHT\n",
    "# [0 0 1 0 0 0 0] = ATTACKS\n",
    "# [0 0 0 1 0 0 0] = MOVE_FORWARD\n",
    "# [0 0 0 0 1 0 0] = MOVE_BACKWARD\n",
    "# [0 0 0 0 0 1 0] = TURN_LEFT\n",
    "# [0 0 0 0 0 0 1] = TURN_RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "12d2675a-be3f-4634-ab3b-33fdbe8b8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:  40.76802062988281\n"
     ]
    }
   ],
   "source": [
    "# Looping through Episodes basically number of times we are going to play the game\n",
    "# episodes = 10\n",
    "episodes = 1\n",
    "for episode in range(episodes):\n",
    "\n",
    "    game.new_episode() # Starting/Restarting the game\n",
    "    while not game.is_episode_finished(): # Checking if game is not finished\n",
    "\n",
    "        # Taking some information about the game:\n",
    "        state = game.get_state() # Getting the game state\n",
    "        img = state.screen_buffer # Getting the actual image in form of 2D or nD arrays to run calculations on\n",
    "        info = state.game_variables # Getting the game variables like Health, Ammo etc. In this case it's AMMO Only\n",
    "        reward = game.make_action(random.choice(actions)) # Taking any random action. (Reward is what we are going to get when we take any action and this is what we are going to get back)\n",
    "        # print(\"Rewards: \", reward) # Printing the reward per frame, Present in the VizDoom README.md\n",
    "        # time.sleep(0.02)\n",
    "    print(\"Result \" + str(episode) + \": \", game.get_total_reward()) # Overall Full game reward and points\n",
    "    time.sleep(2)\n",
    "time.sleep(1)\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbac62b",
   "metadata": {},
   "source": [
    "# Wrapping the game inside a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gym #For VSCode\n",
    "# # or\n",
    "# !pip install gym #For Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeff83d",
   "metadata": {},
   "source": [
    "### OpenAI Gym — Simplified\n",
    "\n",
    "OpenAI Gym is a toolkit that gives you environments where your AI can learn by interacting. It’s like a testing ground where your agent (the AI) sees a state, takes an action, and gets a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01640f5",
   "metadata": {},
   "source": [
    "#### Gym Spaces\n",
    "Discrete: Used when an AI chooses from a small set of fixed actions (e.g., jump, shoot, move left). Ideal for classification-style decisions or simple games. The agent picks one integer to act.\n",
    "\n",
    "Box: Used when an AI needs to handle continuous inputs (e.g., image pixels, sensor values) or produce continuous actions (e.g., steering angle, throttle). The agent handles real numbers across a defined range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c38c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gym import Env\n",
    "# from gym.spaces import Discrete, Box\n",
    "# import cv2 # Will be used to grayscale obzervation for faster processing of VizDoom Environment\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "from vizdoom import DoomGame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca5da9",
   "metadata": {},
   "source": [
    "##### Overview of BOX and DISCRETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d9eaa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For now Think of Discrete as an index for the action between 0 and 2\n",
    "actions[Discrete(7).sample()] # This Discrete is randomly sampleling the input from our action space -OR- action matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af6bc7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 1 0]\n",
      "[0 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# These are 10 such random values from our action space using Discrete Space\n",
    "for i in range(10):\n",
    "    print(actions[Discrete(7).sample()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc01402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  6,  8,  3,  7,  0, 10,  2,  9,  0],\n",
       "       [ 7,  0,  2,  4,  4,  5,  9,  2,  3,  8],\n",
       "       [ 8,  4,  2,  5,  5,  2,  1,  2,  7,  2],\n",
       "       [ 3,  5,  8,  1,  2, 10,  4,  9,  2,  9],\n",
       "       [ 3,  8,  4,  3,  4,  5,  6, 10,  8,  3],\n",
       "       [ 6,  1,  6,  0,  1,  9,  7,  8,  9,  9],\n",
       "       [ 0,  2,  3,  5,  4,  6,  8, 10,  6,  3],\n",
       "       [ 6,  3,  4,  8,  9,  2,  1,  4,  7,  4],\n",
       "       [ 3,  5, 10,  3,  0, 10,  7,  3,  5,  1],\n",
       "       [ 3,  9,  4,  4,  7,  5,  7, 10, 10,  0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Box takes input a low value and a high value and it can return an array of m*n dimensions\n",
    "Box(low=0, high=10, shape=(10,10), dtype=np.uint8).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514779bf",
   "metadata": {},
   "source": [
    "#### Creating VizDoom OpenAI Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4db3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(gym.Env):\n",
    "\n",
    "    # Default Function called during start of Env. In short (setting new episode, setting different spaces etc)\n",
    "    def __init__(self, render=False, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_1.cfg'):\n",
    "        # Inherting from Env\n",
    "        super().__init__()\n",
    "\n",
    "        #Setting up the game\n",
    "        self.game = DoomGame() # Creating game instance\n",
    "        self.game.load_config(config) # Loading the configs like Buttons, MoveSet(Going left or right etc), Bots config etc.\n",
    "\n",
    "        # Render Frame Logic: This is done to train the model faster, because each time if the game is visible it will take more computation and hamper the model training.\n",
    "        # This will start the game in the background as a background process.\n",
    "        if render == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "\n",
    "        self.game.init() # Initializing the Game/Staring the game\n",
    "\n",
    "        # self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        # self.action_space = Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(7)\n",
    "\n",
    "        # Game Variables: \n",
    "        # self.damage_taken = 0\n",
    "        # self.hitcount = 0\n",
    "        # self.selected_weapon_ammo = 52\n",
    "        # self.kill_count = 0\n",
    "\n",
    "        game_variables = self.game.get_state().game_variables\n",
    "        if game_variables is not None and len(game_variables) >= 5:\n",
    "            self.damage_taken = game_variables[1]\n",
    "            self.hitcount = game_variables[2]\n",
    "            self.selected_weapon_ammo = game_variables[3]\n",
    "            self.kill_count = game_variables[4]\n",
    "\n",
    "    # Taking a particular action in environment\n",
    "    def step(self, action):\n",
    "        # Defining the actions MATRIX explained above\n",
    "        actions = np.identity(7, dtype=np.uint8)\n",
    "        # Taking a specific action=\"action\" passed to the step function. The 4 is the frame skip property.\n",
    "        movement_reward = self.game.make_action(actions[action], 4)\n",
    "\n",
    "        reward = 0\n",
    "        if self.game.get_state():\n",
    "        # Taking some information about the game:\n",
    "            state = self.game.get_state().screen_buffer # Getting the actual image in form of 2D or nD arrays to run calculations on\n",
    "            state = self.grayscale(state)\n",
    "\n",
    "            # Reward Shaping:\n",
    "            ## game_variables = self.game.get_state().game_variables # Getting the game variables like Health, Ammo, Hitcount etc.\n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            # health, damage_taken, hitcount, ammo, kill_count = game_variables\n",
    "            if game_variables is not None and len(game_variables) >= 5:\n",
    "                health, damage_taken, hitcount, ammo, kill_count = game_variables\n",
    "            else:\n",
    "                state = np.zeros(self.observation_space.shape)\n",
    "                reward = 0\n",
    "                info = {\"ammo\": None, \"damage_taken\": None, \"hitcount\": None, \"kill_count\": None}\n",
    "\n",
    "\n",
    "            # Calculating Different Delta Parameters:\n",
    "            # Delta: Basically Change from the Previous Frame to the Current Frame\n",
    "            # NEGATIVE REWARDING = DE-INCENTIVISING the model to NOT take actions, which give NEGATIVE REWARDS\n",
    "            # We are negatively rewarding the Model for loosing health over each frame\n",
    "            damage_taken_delta = -damage_taken + self.damage_taken\n",
    "            self.damage_taken = damage_taken\n",
    "\n",
    "            # We are positively rewarding the Model for successful hits over each frame\n",
    "            hitcount_delta = hitcount - self.hitcount\n",
    "            self.hitcount = hitcount\n",
    "\n",
    "            # We are negatively rewarding the Model for loosing/wasting ammo over each frame\n",
    "            if ammo != -1:\n",
    "                ammo_delta = ammo - self.selected_weapon_ammo\n",
    "                self.selected_weapon_ammo = ammo\n",
    "            else:\n",
    "                ammo_delta = 0  # Don't penalize if ammo info is not yet valid\n",
    "\n",
    "            # We are positively rewarding the Model for successful kills over each frame\n",
    "            kill_delta = kill_count - self.kill_count\n",
    "            self.kill_count = kill_count\n",
    "            # NOTE: Hitting a monstor will cause the reward to go UP and loosing/shooting will cause the reward to go DOWN therefore negating each other, hence BALANCING the reward system. \n",
    "\n",
    "            reward = movement_reward + damage_taken_delta*10 + hitcount_delta*200 + ammo_delta*5 + kill_delta*300\n",
    "            info = {\"ammo\": ammo, \"damage_taken\": damage_taken, \"hitcount\": hitcount, \"kill_count\": kill_count}\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            ammo = None  # >>> Make sure ammo is None if no game state\n",
    "            info = {\"ammo\": None, \"damage_taken\": None, \"hitcount\": None, \"kill_count\": None}\n",
    "\n",
    "        terminated = self.game.is_episode_finished() # Returning True or False whether the game is currently running or not (No matter in Background or Not)\n",
    "        truncated = False\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    # Define how to render the game or environment (No Need)\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    # def reset(self, seed=None, options=None):\n",
    "    #     super().reset(seed=seed)\n",
    "    #     self.game.new_episode()\n",
    "    #     state = self.game.get_state().screen_buffer\n",
    "    #     return self.grayscale(state), {}\n",
    "\n",
    "\n",
    "    # def reset(self, seed=None, options=None):\n",
    "    #     super().reset(seed=seed)\n",
    "\n",
    "    #     self.damage_taken = 0\n",
    "    #     self.hitcount = 0\n",
    "    #     self.kill_count = 0\n",
    "    #     self.selected_weapon_ammo = 52\n",
    "\n",
    "    #     self.game.new_episode()\n",
    "    #     state = self.game.get_state().screen_buffer\n",
    "    #     state = self.grayscale(state)\n",
    "\n",
    "    #     return state, {}\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.game.new_episode()\n",
    "\n",
    "        # 🛠 Perform a no-op (or dummy) action to force state update\n",
    "        self.game.make_action([0] * self.action_space.n, 1)\n",
    "\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        game_variables = self.game.get_state().game_variables\n",
    "\n",
    "        if game_variables is not None and len(game_variables) >= 5:\n",
    "            health, damage_taken, hitcount, ammo, kill_count = game_variables\n",
    "            self.damage_taken = damage_taken\n",
    "            self.hitcount = hitcount\n",
    "            self.kill_count = kill_count\n",
    "            self.selected_weapon_ammo = ammo  # ✅ Now ammo will be correct (e.g., 52)\n",
    "            # print(f\"[RESET] Game vars -> Ammo: {ammo}, Damage Taken: {damage_taken}, Hits: {hitcount}, Kills: {kill_count}\")\n",
    "        else:\n",
    "            # print(\"[RESET] Game vars missing or incomplete.\")\n",
    "            pass\n",
    "\n",
    "        state = self.grayscale(state)\n",
    "        return state, {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # To grayscale the game frame and resize it\n",
    "    def grayscale(self, game_frame):\n",
    "        # We moved the axis which means that we changed the shape or REORDERED the matrix.\n",
    "        # This is done because this is the shape in which the cvtColor expects the image\n",
    "        # This is not going to LITERALLY GRAYSCALE the image, but this is instead going to remove the color channel from the \"screen_buffer()\"\n",
    "        # The GRAYSCALED image is just a frame shown using the matplotlib library\n",
    "        gray = cv2.cvtColor(np.moveaxis(game_frame, 0, -1), cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "\n",
    "        # This Resizing and Reshaping is done to cut down the pixel.\n",
    "        # After Reshaping and Resizing we need to process less number of pixels.\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "    \n",
    "        return state\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        # You can set seeds for any random processes your env uses here.\n",
    "        # For example, if DoomGame has a seed method, use it, else just set numpy and random seeds.\n",
    "        import random\n",
    "        import numpy as np\n",
    "\n",
    "        self._seed = seed\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "    # Called to close the game\n",
    "    def close(self):\n",
    "        self.game.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ead29cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae68a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environemnt Checker to check for any bugs or glitches in the Code or Environment\n",
    "from stable_baselines3.common import env_checker\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81876992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 160, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "state.shape # # Only 2 channels are visible here and the 3rd is '1', which means the image have a grayscaled channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "152cb0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2007ef5c080>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e2a34",
   "metadata": {},
   "source": [
    "# Training the REINFORCEMENT LEARNING Model using *CURRICULUM LEARNING*\n",
    "---\n",
    "### I am Going to use PPO-RL Algorithm which is Trained on Actor Critic Algorithm to train my model.\n",
    "#### -> Their are 2 neural networks in Actor Critic Algorithm:\n",
    "#### -> Actor: Controls the Agent Actions\n",
    "#### -> Critic: Tries to Predict the Future Returns from the current state\n",
    "---\n",
    "Basically their are 4 elements:\n",
    "1. Agent: Our Player\n",
    "2. Action: Player Moving Left, Right, Shooting\n",
    "3. Reward: Depending on Actions, get reward\n",
    "4. Environment: The overall environment, enemy location, Agent location etc.\n",
    "\n",
    "AI Controlling the Agent learns what actions to take in Environment in order to maximize the reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ff3f8",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137512ef",
   "metadata": {},
   "source": [
    "### Working of my Algorithm:\n",
    "\n",
    "**Step 1:** We get the observation (current frame) from our game.\n",
    "\n",
    "**Step 2:** That frame is passed to both Actor and Critic:\n",
    "- **Actor** outputs a set of probabilities for what actions to take.\n",
    "- **Critic** outputs expected future returns from the current state.\n",
    "\n",
    "**Step 3:** Using the Actor output, we select an action and perform it.\n",
    "- The **observation**, **reward**, **action**, **value**, and **probabilities** are all stored in a temporary buffer.\n",
    "\n",
    "**Step 4:** This continues until the game is done or the maximum game length is reached.\n",
    "\n",
    "**Step 5:** After collecting all the data, we use it to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee705cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Pytorch:\n",
    "\n",
    "# For Notebooks\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# OR\n",
    "\n",
    "# For VS Code\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a898a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Stable-Baselines for PPO Algorithm:\n",
    "\n",
    "# For Notebooks\n",
    "# !pip install stable-baselines3[extra]\n",
    "\n",
    "# OR\n",
    "\n",
    "# For VS Code\n",
    "# %pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94c0d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch:  2.6.0+cu118\n",
      "Stable Baseline:  2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Checking for Installations\n",
    "import torch\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "print(\"Pytorch: \", torch.__version__)\n",
    "print(\"Stable Baseline: \", stable_baselines3.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa69a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For navigating folders\n",
    "# Lets you insert custom code during training in Stable-Baselines3. It's used for tasks like saving best models, early stopping, or logging custom metrics.\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f919",
   "metadata": {},
   "source": [
    "##### Class to Automatically Save the RL Model Every Few Steps During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97b913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseCallback: Saves the model regularly during training so model don’t lose progress if something crashes.\n",
    "class TrainAndLoggingCallback(BaseCallback):  # Custom callback extending BaseCallback for periodic model saving\n",
    "    def __init__(self, check_freq, save_path, verbose = 1):  # Initialize callback with save frequency and path\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)  # Call parent constructor with verbosity setting\n",
    "        self.check_freq = check_freq  # Set how often to save the model\n",
    "        self.save_path = save_path  # Set the directory to save models\n",
    "        \n",
    "    def _init_callback(self):  # Called at the beginning of training\n",
    "        if self.save_path is not None:  # Ensure save_path is defined\n",
    "            os.makedirs(self.save_path, exist_ok=True)  # Create save directory if it doesn't exist\n",
    "    \n",
    "    def _on_step(self):  # Called at every step during training\n",
    "        if self.n_calls % self.check_freq == 0:  # Check if current step is a checkpoint\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls)) # Constructs the full file path to save the model, inside the specified save_path directory. This enables saving multiple model versions at regular intervals during training for later evaluation.\n",
    "            self.model.save(model_path)  # Save current model to the constructed path\n",
    "        return True  # Continue training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89c3a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_corridor' # Directory for saving our trained RL Model\n",
    "LOG_DIR = './logs/log_corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b01b4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of our Training and Logging Callback\n",
    "# This means after every 10,000 steps of training the model, we are going to save the version of those PyTorch Weights of our RL Agent.\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7185c36",
   "metadata": {},
   "source": [
    "### Actually Training the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9078dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PPO for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bfdd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Model is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(seed=0):\n",
    "    def _init():\n",
    "        env = VizDoomGym(render=False, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_1.cfg')\n",
    "        env.seed(seed)\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "env = DummyVecEnv([make_env(seed=SEED)])  # Single env wrapped in DummyVecEnv with Monitor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = PPO(\n",
    "    'CnnPolicy',\n",
    "    env,\n",
    "    tensorboard_log=LOG_DIR,\n",
    "    verbose=1,\n",
    "    learning_rate=0.00001,\n",
    "    n_steps=8192,\n",
    "    clip_range=.1,\n",
    "    gamma=.95,\n",
    "    gae_lambda=.9,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    device=device,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(\"Model is on:\", model.policy.device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'CnnPolicy': Uses a convolutional neural network, used for processing image-based observations like game frames.\n",
    "# env: The environment where the agent learns and acts; must follow the Gymnasium API.\n",
    "# tensorboard_log=LOG_DIR: Specifies the path to save logs for visualizing training metrics using TensorBoard.\n",
    "# verbose=1: Enables informational output during training; helps monitor progress in the console.\n",
    "# learning_rate=0.0001: Controls how quickly the model updates its knowledge; lower values lead to more stable learning.\n",
    "# n_steps=2048: Number of environment steps to run (frames to store) before each policy update; affects training stability and memory use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4464178",
   "metadata": {},
   "source": [
    "# Note: \n",
    "### Only Run this code cell if you want to train the model. Otherwise don't. Skip to Testing directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff013a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_corridor\\PPO_6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | 90.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 46       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | 13.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 55           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035003899 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -1.66e-05    |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.95e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 6.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 161          |\n",
      "|    ep_rew_mean          | -187         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029159891 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00284      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 7.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 127          |\n",
      "|    ep_rew_mean          | -255         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025201687 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.41e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.06e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -149         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 643          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025757656 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.63e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.04e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -70.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 761          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027887938 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.0605       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.73e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.1         |\n",
      "|    ep_rew_mean          | -77          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 881          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027651626 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | 0.0951       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.38e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.19e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.6         |\n",
      "|    ep_rew_mean          | 43.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1000         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026921756 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.1e+03      |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93           |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1119         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021870025 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.37e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 1.48e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88           |\n",
      "|    ep_rew_mean          | 177          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1238         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027001137 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.84e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 1.54e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91           |\n",
      "|    ep_rew_mean          | 249          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1358         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031690714 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+04     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.65e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.2         |\n",
      "|    ep_rew_mean          | 246          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1477         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030022399 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.74e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 1.78e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.8       |\n",
      "|    ep_rew_mean          | 343        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 1598       |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00327944 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 8e+03      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0014    |\n",
      "|    value_loss           | 1.8e+04    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.3         |\n",
      "|    ep_rew_mean          | 417          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1717         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035377024 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.35e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 1.92e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74          |\n",
      "|    ep_rew_mean          | 435         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1837        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003416539 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.06e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 1.98e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76          |\n",
      "|    ep_rew_mean          | 454         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1956        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003220051 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.91e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.5         |\n",
      "|    ep_rew_mean          | 504          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2075         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030588573 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.195        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.51e+04     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000769    |\n",
      "|    value_loss           | 2.1e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70.7         |\n",
      "|    ep_rew_mean          | 485          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2195         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032042502 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.49e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00064     |\n",
      "|    value_loss           | 2.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74           |\n",
      "|    ep_rew_mean          | 606          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2316         |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035295184 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.61e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 2.21e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.9        |\n",
      "|    ep_rew_mean          | 609         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2436        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003468663 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.44e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    value_loss           | 2.25e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.8         |\n",
      "|    ep_rew_mean          | 768          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2558         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029551587 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 2.16e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69           |\n",
      "|    ep_rew_mean          | 802          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2675         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027126453 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.11e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000725    |\n",
      "|    value_loss           | 2.3e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.7        |\n",
      "|    ep_rew_mean          | 773         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2795        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003207108 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.5e+04     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    value_loss           | 2.52e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.1         |\n",
      "|    ep_rew_mean          | 1.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2915         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029959567 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.14e+03     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000363    |\n",
      "|    value_loss           | 2.47e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.1         |\n",
      "|    ep_rew_mean          | 887          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 3034         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035230862 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.278        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27f90f62750>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54062a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49       |\n",
      "|    ep_rew_mean     | 527      |\n",
      "| time/              |          |\n",
      "|    fps             | 89       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45          |\n",
      "|    ep_rew_mean          | 394         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006547937 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.8e+04     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.000906    |\n",
      "|    value_loss           | 3.37e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.2         |\n",
      "|    ep_rew_mean          | 642          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043001086 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.46e+04     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -8.4e-05     |\n",
      "|    value_loss           | 3.2e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.1         |\n",
      "|    ep_rew_mean          | 686          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 450          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064142556 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000978    |\n",
      "|    value_loss           | 3.2e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.3         |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 570          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048018526 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.42e+04     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.000219     |\n",
      "|    value_loss           | 3.05e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.2         |\n",
      "|    ep_rew_mean          | 654          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040692473 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.32e+04     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.000294     |\n",
      "|    value_loss           | 3.06e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.6         |\n",
      "|    ep_rew_mean          | 929          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 812          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058510504 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.37e+04     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.000992     |\n",
      "|    value_loss           | 2.92e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.4         |\n",
      "|    ep_rew_mean          | 826          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 932          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044464692 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.838       |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | 0.00202      |\n",
      "|    value_loss           | 2.61e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.8        |\n",
      "|    ep_rew_mean          | 820         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005631021 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.13e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    value_loss           | 2.53e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.3        |\n",
      "|    ep_rew_mean          | 966         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1172        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987215 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.05e+04    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    value_loss           | 2.22e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.8         |\n",
      "|    ep_rew_mean          | 906          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1292         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052684774 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.659       |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.11e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | 0.00199      |\n",
      "|    value_loss           | 2.2e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.1         |\n",
      "|    ep_rew_mean          | 962          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1413         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044836346 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.646       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.26e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.0034       |\n",
      "|    value_loss           | 2.32e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.9        |\n",
      "|    ep_rew_mean          | 926         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1532        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004806496 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.03e+04    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    value_loss           | 2.1e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.4         |\n",
      "|    ep_rew_mean          | 963          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035281968 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.34e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.00333      |\n",
      "|    value_loss           | 2.35e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49           |\n",
      "|    ep_rew_mean          | 976          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1771         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041511985 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.00367      |\n",
      "|    value_loss           | 2.11e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.4         |\n",
      "|    ep_rew_mean          | 1.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1893         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057656323 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.12e+03     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.00292      |\n",
      "|    value_loss           | 2.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.6         |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2014         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047740177 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.08e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.00374      |\n",
      "|    value_loss           | 2.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.8         |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2135         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032164098 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.26e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 0.00254      |\n",
      "|    value_loss           | 1.97e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.6         |\n",
      "|    ep_rew_mean          | 1.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2254         |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038434234 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.00498      |\n",
      "|    value_loss           | 1.91e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.9         |\n",
      "|    ep_rew_mean          | 1.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2374         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035786214 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.94e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.00436      |\n",
      "|    value_loss           | 1.83e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 55.4        |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2494        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004411782 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.22e+04    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    value_loss           | 1.98e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.8        |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2613        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003961039 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.04e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00271     |\n",
      "|    value_loss           | 1.71e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51           |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2734         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048679207 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.19e+04     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | 0.00572      |\n",
      "|    value_loss           | 1.82e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.3         |\n",
      "|    ep_rew_mean          | 1.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2854         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044866493 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.91e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00255      |\n",
      "|    value_loss           | 1.74e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.9         |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2974         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052832454 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.48e+03     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.00481      |\n",
      "|    value_loss           | 1.68e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27f90f62750>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = VizDoomGym(config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_2.cfg')\n",
    "# model.set_env(env)\n",
    "# model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058c28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 54.5     |\n",
      "|    ep_rew_mean     | 1.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 90       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 56.4         |\n",
      "|    ep_rew_mean          | 1.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060805636 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.42e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 0.00566      |\n",
      "|    value_loss           | 1.64e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.7         |\n",
      "|    ep_rew_mean          | 1.21e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 332          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035181786 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.29        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.1e+03      |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.0024       |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002929335 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.85e+03    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    value_loss           | 1.43e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.6         |\n",
      "|    ep_rew_mean          | 1.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 573          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037390655 |\n",
      "|    clip_fraction        | 0.0868       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.281       |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.91e+03     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 0.00375      |\n",
      "|    value_loss           | 1.46e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.8         |\n",
      "|    ep_rew_mean          | 1.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026238356 |\n",
      "|    clip_fraction        | 0.0805       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.281       |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.33e+03     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | 0.00318      |\n",
      "|    value_loss           | 1.56e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 55.5       |\n",
      "|    ep_rew_mean          | 1.32e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 70         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 814        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00457172 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 8.84e+03   |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | 0.00358    |\n",
      "|    value_loss           | 1.54e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.2        |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004029288 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.22e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.00509     |\n",
      "|    value_loss           | 1.64e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.2         |\n",
      "|    ep_rew_mean          | 1.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1053         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062802974 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.313       |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.89e+04     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | 0.00312      |\n",
      "|    value_loss           | 1.79e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 55.6         |\n",
      "|    ep_rew_mean          | 1.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1172         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048546474 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.9e+03      |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.0052       |\n",
      "|    value_loss           | 1.53e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.1        |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004998087 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.22e+03    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 0.00313     |\n",
      "|    value_loss           | 1.78e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 55.9        |\n",
      "|    ep_rew_mean          | 1.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1412        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006162268 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.39e+04    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00452     |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.7         |\n",
      "|    ep_rew_mean          | 1.56e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1532         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043135723 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.19e+03     |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | 0.00286      |\n",
      "|    value_loss           | 1.98e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.7         |\n",
      "|    ep_rew_mean          | 1.61e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1653         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052061174 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.336       |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.11e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00468      |\n",
      "|    value_loss           | 1.71e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.5         |\n",
      "|    ep_rew_mean          | 1.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1772         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034579444 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.346       |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.89e+03     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.00309      |\n",
      "|    value_loss           | 1.92e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 1.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1891         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057424437 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.335       |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.97e+03     |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | 0.00354      |\n",
      "|    value_loss           | 1.8e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.4         |\n",
      "|    ep_rew_mean          | 1.8e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2009         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063326694 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.348       |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.07e+04     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | 0.00517      |\n",
      "|    value_loss           | 1.49e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.3       |\n",
      "|    ep_rew_mean          | 1.64e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 69         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 2128       |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00452974 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.358     |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.63e+04   |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | 0.0082     |\n",
      "|    value_loss           | 1.87e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.3         |\n",
      "|    ep_rew_mean          | 1.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2246         |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046182866 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.347       |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.85e+03     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | 0.00445      |\n",
      "|    value_loss           | 2.14e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.3        |\n",
      "|    ep_rew_mean          | 1.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2367        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006637651 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.91e+03    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    value_loss           | 2.15e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.9        |\n",
      "|    ep_rew_mean          | 1.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005680465 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.42e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.00757     |\n",
      "|    value_loss           | 2.05e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 63.2         |\n",
      "|    ep_rew_mean          | 1.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2605         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031948937 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.284       |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.82e+04     |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | 0.00189      |\n",
      "|    value_loss           | 2.22e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 63.9         |\n",
      "|    ep_rew_mean          | 1.9e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2725         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070056403 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.29e+04     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | 0.00377      |\n",
      "|    value_loss           | 2.2e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69          |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2845        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005217327 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.6e+04     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00402     |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.4        |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2966        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003635868 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | 0.00362     |\n",
      "|    value_loss           | 2.13e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27f90f62750>"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = VizDoomGym(config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_3.cfg')\n",
    "# model.set_env(env)\n",
    "# model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e39b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 65.6     |\n",
      "|    ep_rew_mean     | 2.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 89       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 63.9        |\n",
      "|    ep_rew_mean          | 1.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005686119 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.25e+04    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00841     |\n",
      "|    value_loss           | 2.38e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.8        |\n",
      "|    ep_rew_mean          | 1.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003956172 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.21e+04    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    value_loss           | 2.26e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.6         |\n",
      "|    ep_rew_mean          | 2.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 72           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 449          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063746586 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.247       |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | 0.00408      |\n",
      "|    value_loss           | 2.44e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 63         |\n",
      "|    ep_rew_mean          | 2.01e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 71         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 569        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01025566 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 7.62e+03   |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.0114     |\n",
      "|    value_loss           | 1.87e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.9         |\n",
      "|    ep_rew_mean          | 1.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 687          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070796954 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.272       |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.7e+03      |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | 0.0033       |\n",
      "|    value_loss           | 2.08e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.9        |\n",
      "|    ep_rew_mean          | 2.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009198749 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.56e+03    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.00542     |\n",
      "|    value_loss           | 2.56e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.6         |\n",
      "|    ep_rew_mean          | 2.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 925          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031466167 |\n",
      "|    clip_fraction        | 0.0796       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.224       |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.99e+03     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | 0.0016       |\n",
      "|    value_loss           | 2.26e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.2         |\n",
      "|    ep_rew_mean          | 2.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1044         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031394307 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.24e+04     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | 0.00251      |\n",
      "|    value_loss           | 2.43e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65.2         |\n",
      "|    ep_rew_mean          | 2.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1165         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028819027 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.223       |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.28e+04     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | 0.00219      |\n",
      "|    value_loss           | 2.38e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.4        |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004635413 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.22e+04    |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00328     |\n",
      "|    value_loss           | 2.28e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 62.8       |\n",
      "|    ep_rew_mean          | 2.16e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 69         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 1404       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00411622 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.212     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 6.71e+03   |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | 0.00258    |\n",
      "|    value_loss           | 2.24e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 63.2        |\n",
      "|    ep_rew_mean          | 2.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1524        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004165076 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.15e+03    |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    value_loss           | 1.89e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 63.3         |\n",
      "|    ep_rew_mean          | 2.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1644         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028927377 |\n",
      "|    clip_fraction        | 0.0725       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.9e+03      |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | 0.00261      |\n",
      "|    value_loss           | 1.95e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.1        |\n",
      "|    ep_rew_mean          | 2e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004329214 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.189      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.54e+03    |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    value_loss           | 2.05e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.9         |\n",
      "|    ep_rew_mean          | 2.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1884         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072463094 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.193       |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.93e+03     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | 0.0052       |\n",
      "|    value_loss           | 1.75e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.5         |\n",
      "|    ep_rew_mean          | 2.17e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2003         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055226814 |\n",
      "|    clip_fraction        | 0.0867       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.96e+03     |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 0.00387      |\n",
      "|    value_loss           | 1.73e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 2.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2123        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003613056 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.8e+03     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.9        |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2243        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002492446 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.32e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00295     |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61           |\n",
      "|    ep_rew_mean          | 2.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2364         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025647562 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.83e+03     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | 0.0019       |\n",
      "|    value_loss           | 1.67e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.5        |\n",
      "|    ep_rew_mean          | 2.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2484        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002462724 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.169      |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.52e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.000421    |\n",
      "|    value_loss           | 1.4e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64           |\n",
      "|    ep_rew_mean          | 2.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2606         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030186228 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.87e+03     |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | 0.00249      |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.2         |\n",
      "|    ep_rew_mean          | 2.1e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2725         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034726528 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.178       |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.58e+03     |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | 0.00273      |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.7         |\n",
      "|    ep_rew_mean          | 2.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2843         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036153088 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.69e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | 0.00316      |\n",
      "|    value_loss           | 1.5e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.2         |\n",
      "|    ep_rew_mean          | 2.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2963         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054458105 |\n",
      "|    clip_fraction        | 0.0764       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.164       |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.5e+03      |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    value_loss           | 1.62e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27f90f62750>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = VizDoomGym(config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_4.cfg')\n",
    "# model.set_env(env)\n",
    "# model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f69381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_corridor\\PPO_10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.4     |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    fps             | 87       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.7        |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016367553 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.63e+04    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | 0.0298      |\n",
      "|    value_loss           | 2.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.8        |\n",
      "|    ep_rew_mean          | 295         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006534876 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.201      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.55e+03    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.00636     |\n",
      "|    value_loss           | 2.1e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.9        |\n",
      "|    ep_rew_mean          | 304         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004364625 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.58e+03    |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.6         |\n",
      "|    ep_rew_mean          | 371          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 577          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056223013 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.257       |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.98e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.000256    |\n",
      "|    value_loss           | 2e+04        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | 464         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009427624 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.04e+04    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    value_loss           | 1.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | 533         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611977 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.5e+03     |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | 0.000964    |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.8        |\n",
      "|    ep_rew_mean          | 665         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 940         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009477388 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.62e+03    |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.000126    |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.7         |\n",
      "|    ep_rew_mean          | 611          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1063         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072476193 |\n",
      "|    clip_fraction        | 0.0946       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.19        |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.61e+03     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 1.36e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.8         |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1182         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047829608 |\n",
      "|    clip_fraction        | 0.0731       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.66e+03     |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.000322    |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.4         |\n",
      "|    ep_rew_mean          | 718          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055386173 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.35e+03     |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | 0.000972     |\n",
      "|    value_loss           | 1.26e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.3        |\n",
      "|    ep_rew_mean          | 771         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1422        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004316541 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.73e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000103   |\n",
      "|    value_loss           | 1.07e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.8         |\n",
      "|    ep_rew_mean          | 697          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1542         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038829115 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.202       |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.55e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | 0.0037       |\n",
      "|    value_loss           | 1.21e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.8        |\n",
      "|    ep_rew_mean          | 713         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1664        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003744775 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.28e+03    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 38           |\n",
      "|    ep_rew_mean          | 812          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1785         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033363556 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.14e+03     |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | 1.89e-05     |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.6         |\n",
      "|    ep_rew_mean          | 770          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1907         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040250574 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+04     |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | 0.00127      |\n",
      "|    value_loss           | 1.33e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.4         |\n",
      "|    ep_rew_mean          | 815          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 2026         |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036454303 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.07e+03     |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | 0.000961     |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.1         |\n",
      "|    ep_rew_mean          | 775          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2149         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042989566 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.18        |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.77e+03     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | 0.00138      |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.6        |\n",
      "|    ep_rew_mean          | 704         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2269        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004729833 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | 3.3e-05     |\n",
      "|    value_loss           | 1.11e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39.4         |\n",
      "|    ep_rew_mean          | 825          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2391         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040724226 |\n",
      "|    clip_fraction        | 0.0725       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.163       |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.05e+03     |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000175    |\n",
      "|    value_loss           | 1.04e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.9         |\n",
      "|    ep_rew_mean          | 832          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2511         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027936841 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.22e+03     |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | 0.000139     |\n",
      "|    value_loss           | 1.29e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.1         |\n",
      "|    ep_rew_mean          | 888          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2632         |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030592205 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.162       |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.27e+03     |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | 0.000631     |\n",
      "|    value_loss           | 1.24e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 38.5         |\n",
      "|    ep_rew_mean          | 903          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2752         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056023183 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.17        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.12e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | 0.00287      |\n",
      "|    value_loss           | 1.32e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.2        |\n",
      "|    ep_rew_mean          | 1.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003819819 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.77e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.000988    |\n",
      "|    value_loss           | 1.23e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39.7         |\n",
      "|    ep_rew_mean          | 970          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2993         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059939357 |\n",
      "|    clip_fraction        | 0.0996       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.217       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.15e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | 0.00652      |\n",
      "|    value_loss           | 1.36e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x27f90f62750>"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env = VizDoomGym(config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_5.cfg')\n",
    "# model.set_env(env)\n",
    "# model.learn(total_timesteps=200000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934eb11",
   "metadata": {},
   "source": [
    "# Testing the RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "167084ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Evaluate_Policy to Test the Agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342faec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model (from Disk), the total trained list. In my case the latest model present in directory is loaded\n",
    "model = PPO.load('./deadly_corridor_1110000')\n",
    "env = VizDoomGym(render=True) # Rendered Environment for Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a771796",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=3) # Evaluating Mean Reward for 10 games of DOOM!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b10410b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516.1768239339192"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1: 1216.355728149414\n",
      "Total Reward for episode 2: 1676.900650024414\n",
      "Total Reward for episode 3: 1174.2869415283203\n",
      "Total Reward for episode 4: 2709.644073486328\n",
      "Total Reward for episode 5: 1216.355728149414\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "for episode in range(5):\n",
    "    obs = env.reset()[0]\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    start_time = time.time()  # Track start time of episode\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Check if the episode is running too long\n",
    "        if time.time() - start_time > 90:\n",
    "            print(f\"Episode {episode + 1} terminated after 30 seconds.\")\n",
    "            done = True\n",
    "\n",
    "        time.sleep(0.15)\n",
    "        total_reward += reward  # reward is a vector from DummyVecEnv\n",
    "\n",
    "    print(f\"Total Reward for episode {episode + 1}: {total_reward}\")\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccccb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 1\n",
    "# env1 = VizDoomGym(render=True, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_1.cfg')\n",
    "\n",
    "# Level 2\n",
    "env2 = VizDoomGym(render=True, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_2.cfg')\n",
    "\n",
    "# Level 3\n",
    "# env3 = VizDoomGym(render=True, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_3.cfg')\n",
    "\n",
    "# Level 4\n",
    "# env4 = VizDoomGym(render=True, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_4.cfg')\n",
    "\n",
    "# Level 5\n",
    "# env5 = VizDoomGym(render=True, config='github/ViZDoom/scenarios/deadly_corridor_cfgs/deadly_corridor_custom_5.cfg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env2.reset()  # ← now testing on level 2\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env2.step(action)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
