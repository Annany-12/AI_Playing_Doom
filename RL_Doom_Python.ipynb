{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2d0882",
   "metadata": {},
   "source": [
    "# Setting Up VizDoom Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5890935-a340-4594-91b1-faf10017eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making an AI Model to play Doom using Reinforcement Learning\n"
     ]
    }
   ],
   "source": [
    "print(\"Making an AI Model to play Doom using Reinforcement Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff8ce04-0bfe-45f3-a091-92a9bdaefa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Vizdoom:\n",
    "# %pip install vizdoom #For VSCode\n",
    "# # OR\n",
    "# !pip install vizdoom #For Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308191ca-e4d4-4273-b61d-b3e4dede6add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git #For VSCode\n",
    "# # OR\n",
    "# !cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git #For Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "aa8e0dc3-03b2-4420-8402-291dbb748cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "26609d82-3284-4263-ad2f-d3400e5c8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame() # Creating game instance\n",
    "game.load_config('github/ViZDoom/scenarios/basic.cfg') # Loading the configs like Buttons, MoveSet(Going left or right etc), Bots config etc.\n",
    "game.init() # Initializing the Game/Staring the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "775aaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "42bb576e-640f-42f1-b9c3-bde0b5c6a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to take actions in the game, based on Identity Matrix.\n",
    "# Note: Regarding how the actions work, in the basic.cfg file at line 28 we can see:\n",
    "\n",
    "    # available_buttons = {\n",
    "    #     MOVE_LEFT\n",
    "    #     MOVE_RIGHT\n",
    "    #     ATTACK\n",
    "    # }\n",
    "\n",
    "# Now to take actions we pass them as an array to the model or to python in general. For example:\n",
    "# 1. To take MOVE_LEFT action we pass the array [1,0,0] to python.\n",
    "# 2. To take MOVE_RIGHT action we pass the array [0,1,0] to python.\n",
    "# 3. To take ATTACK action we pass the array [0,0,1] to python.\n",
    "\n",
    "actions = np.identity(3, dtype=np.uint8)\n",
    "# Here actions matrix is:\n",
    "       # [[1, 0, 0],\n",
    "       # [0, 1, 0],\n",
    "       # [0, 0, 1]]\n",
    "# Therefore:\n",
    "    # Here actions[0] = [1, 0, 0] i.e. MOVE_LEFT\n",
    "    # Here actions[1] = [0, 1, 0] i.e. MOVE_RIGHT\n",
    "    # Here actions[2] = [0, 0, 1] i.e. ATTACK\n",
    "\n",
    "# We randomly select any action to pass into the game for now\n",
    "print(actions)\n",
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079e8c1",
   "metadata": {},
   "source": [
    "### Taking Random Actions just to see, if the env is working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2675a-be3f-4634-ab3b-33fdbe8b8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  1.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  -1.0\n",
      "Result 0:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  1.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  1.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  0.0\n",
      "Rewards:  -1.0\n",
      "Result 1:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Looping through Episodes basically number of times we are going to play the game\n",
    "# episodes = 10\n",
    "episodes = 2\n",
    "for episode in range(episodes):\n",
    "\n",
    "    game.new_episode() # Starting/Restarting the game\n",
    "    while not game.is_episode_finished(): # Checking if game is not finished\n",
    "\n",
    "        # Taking some information about the game:\n",
    "        state = game.get_state() # Getting the game state\n",
    "        img = state.screen_buffer # Getting the actual image in form of 2D or nD arrays to run calculations on\n",
    "        info = state.game_variables # Getting the game variables like Health, Ammo etc. In this case it's AMMO Only\n",
    "        reward = game.make_action(random.choice(actions)) # Taking any random action. (Reward is what we are going to get when we take any action and this is what we are going to get back)\n",
    "        time.sleep(0.02) \n",
    "    print(\"Result \" + str(episode) + \": \", game.get_total_reward()) # Overall Full game reward and points\n",
    "    time.sleep(2)\n",
    "time.sleep(1)\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbac62b",
   "metadata": {},
   "source": [
    "# Wrapping the game inside a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gym #For VSCode\n",
    "# # or\n",
    "# !pip install gym #For Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeff83d",
   "metadata": {},
   "source": [
    "### OpenAI Gym — Simplified\n",
    "\n",
    "OpenAI Gym is a toolkit that gives you environments where your AI can learn by interacting. It’s like a testing ground where your agent (the AI) sees a state, takes an action, and gets a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01640f5",
   "metadata": {},
   "source": [
    "#### Gym Spaces\n",
    "Discrete: Used when an AI chooses from a small set of fixed actions (e.g., jump, shoot, move left). Ideal for classification-style decisions or simple games. The agent picks one integer to act.\n",
    "\n",
    "Box: Used when an AI needs to handle continuous inputs (e.g., image pixels, sensor values) or produce continuous actions (e.g., steering angle, throttle). The agent handles real numbers across a defined range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c38c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gym import Env\n",
    "# from gym.spaces import Discrete, Box\n",
    "# import cv2 # Will be used to grayscale obzervation for faster processing of VizDoom Environment\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "from vizdoom import DoomGame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca5da9",
   "metadata": {},
   "source": [
    "##### Overview of BOX and DISCRETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9eaa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For now Think of Discrete as an index for the action between 0 and 2\n",
    "actions[Discrete(3).sample()] # This Discrete is randomly sampleling the input from our action space -OR- action matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6bc7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[1 0 0]\n",
      "[1 0 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n",
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# These are 10 such random values from our action space using Discrete Space\n",
    "for i in range(10):\n",
    "    print(actions[Discrete(3).sample()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc01402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  4, 10,  3,  6,  7,  3,  7,  0,  2],\n",
       "       [ 0,  3,  4,  1,  0,  8,  7, 10,  1,  2],\n",
       "       [10,  6,  6,  1,  9,  1,  8,  7,  6,  3],\n",
       "       [ 5,  7,  6, 10,  7,  9,  9, 10,  5,  0],\n",
       "       [ 7,  0,  9,  4,  7, 10, 10,  1,  6,  7],\n",
       "       [ 0,  5,  3,  2,  3,  7,  5,  6,  4, 10],\n",
       "       [ 9, 10,  9,  0,  4,  0,  0,  2,  3,  0],\n",
       "       [ 7,  5,  2,  4,  7,  9,  9, 10,  9, 10],\n",
       "       [ 4,  0,  5, 10,  7,  8, 10, 10,  9,  4],\n",
       "       [ 0,  2,  7, 10, 10, 10, 10,  4,  1,  2]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Box takes input a low value and a high value and it can return an array of m*n dimensions\n",
    "Box(low=0, high=10, shape=(10,10), dtype=np.uint8).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514779bf",
   "metadata": {},
   "source": [
    "#### Creating VizDoom OpenAI Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4db3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(gym.Env):\n",
    "\n",
    "    # Default Function called during start of Env. In short (setting new episode, setting different spaces etc)\n",
    "    def __init__(self, render=False):\n",
    "        # Inherting from Env\n",
    "        super().__init__()\n",
    "\n",
    "        #Setting up the game\n",
    "        self.game = DoomGame() # Creating game instance\n",
    "        self.game.load_config('github/ViZDoom/scenarios/basic.cfg') # Loading the configs like Buttons, MoveSet(Going left or right etc), Bots config etc.\n",
    "\n",
    "        # Render Frame Logic: This is done to train the model faster, because each time if the game is visible it will take more computation and hamper the model training.\n",
    "        # This will start the game in the background as a background process.\n",
    "        if render == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "\n",
    "        self.game.init() # Initializing the Game/Staring the game\n",
    "\n",
    "        # self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        # self.action_space = Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self.prev_ammo = None  # Initialize ammo tracker to None\n",
    "\n",
    "    # Taking a particular action in environment\n",
    "    def step(self, action):\n",
    "        # Defining the actions MATRIX explained above\n",
    "        actions = np.identity(3, dtype=np.uint8)\n",
    "        # Taking a specific action=\"action\" passed to the step function. The 4 is the frame skip property.\n",
    "        reward = self.game.make_action(actions[action], 4)\n",
    "\n",
    "        if self.game.get_state():\n",
    "        # Taking some information about the game:\n",
    "            state = self.game.get_state().screen_buffer # Getting the actual image in form of 2D or nD arrays to run calculations on\n",
    "            state = self.grayscale(state)\n",
    "            # info = self.game.get_state().game_variables # Getting the game variables like Health, Ammo etc. In this case it's AMMO Only\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = {\"ammo\": ammo}\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            ammo = None  # >>> Make sure ammo is None if no game state\n",
    "            info = {\"ammo\": None}\n",
    "\n",
    "        # Reward shaping: Penalize ammo usage to avoid random shooting >>> Added below\n",
    "        if self.prev_ammo is not None and ammo is not None:\n",
    "            ammo_used = self.prev_ammo - ammo\n",
    "            if ammo_used > 0:\n",
    "                # Penalize wasted shots (0.1 per ammo used)\n",
    "                reward -= 0.1 * ammo_used\n",
    "            else:\n",
    "                # Bonus small reward for conserving ammo\n",
    "                reward += 0.05\n",
    "        self.prev_ammo = ammo  # Update ammo tracker for next step\n",
    "\n",
    "        terminated = self.game.is_episode_finished() # Returning True or False whether the game is currently running or not (No matter in Background or Not)\n",
    "        truncated = False\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    # Define how to render the game or environment (No Need)\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        # Initialize ammo tracking at reset >>> Added below\n",
    "        self.prev_ammo = self.game.get_state().game_variables[0]\n",
    "        return self.grayscale(state), {}\n",
    "\n",
    "    # To grayscale the game frame and resize it\n",
    "    def grayscale(self, game_frame):\n",
    "        # We moved the axis which means that we changed the shape or REORDERED the matrix.\n",
    "        # This is done because this is the shape in which the cvtColor expects the image\n",
    "        # This is not going to LITERALLY GRAYSCALE the image, but this is instead going to remove the color channel from the \"screen_buffer()\"\n",
    "        # The GRAYSCALED image is just a frame shown using the matplotlib library\n",
    "        gray = cv2.cvtColor(np.moveaxis(game_frame, 0, -1), cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "\n",
    "        # This Resizing and Reshaping is done to cut down the pixel.\n",
    "        # After Reshaping and Resizing we need to process less number of pixels.\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "    \n",
    "        return state\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        # You can set seeds for any random processes your env uses here.\n",
    "        # For example, if DoomGame has a seed method, use it, else just set numpy and random seeds.\n",
    "        import random\n",
    "        import numpy as np\n",
    "\n",
    "        self._seed = seed\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "    # Called to close the game\n",
    "    def close(self):\n",
    "        self.game.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ead29cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ae68a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environemnt Checker to check for any bugs or glitches in the Code or Environment\n",
    "from stable_baselines3.common import env_checker\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81876992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 160, 1)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "state.shape # Only 2 channels are visible here and the 3rd is '1', which means the image have a grayscaled channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\annan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "152cb0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eb8a5ffbf0>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e2a34",
   "metadata": {},
   "source": [
    "# Training the REINFORCEMENT LEARNING Model\n",
    "---\n",
    "### I am Going to use PPO-RL Algorithm which is Trained on Actor Critic Algorithm to train my model.\n",
    "#### -> Their are 2 neural networks in Actor Critic Algorithm:\n",
    "#### -> Actor: Controls the Agent Actions\n",
    "#### -> Critic: Tries to Predict the Future Returns from the current state\n",
    "---\n",
    "Basically their are 4 elements:\n",
    "1. Agent: Our Player\n",
    "2. Action: Player Moving Left, Right, Shooting\n",
    "3. Reward: Depending on Actions, get reward\n",
    "4. Environment: The overall environment, enemy location, Agent location etc.\n",
    "\n",
    "AI Controlling the Agent learns what actions to take in Environment in order to maximize the reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ff3f8",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137512ef",
   "metadata": {},
   "source": [
    "### Working of my Algorithm:\n",
    "\n",
    "**Step 1:** We get the observation (current frame) from our game.\n",
    "\n",
    "**Step 2:** That frame is passed to both Actor and Critic:\n",
    "- **Actor** outputs a set of probabilities for what actions to take.\n",
    "- **Critic** outputs expected future returns from the current state.\n",
    "\n",
    "**Step 3:** Using the Actor output, we select an action and perform it.\n",
    "- The **observation**, **reward**, **action**, **value**, and **probabilities** are all stored in a temporary buffer.\n",
    "\n",
    "**Step 4:** This continues until the game is done or the maximum game length is reached.\n",
    "\n",
    "**Step 5:** After collecting all the data, we use it to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee705cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Pytorch:\n",
    "\n",
    "# For Notebooks\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# OR\n",
    "\n",
    "# For VS Code\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a898a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Stable-Baselines for PPO Algorithm:\n",
    "\n",
    "# For Notebooks\n",
    "# !pip install stable-baselines3[extra]\n",
    "\n",
    "# OR\n",
    "\n",
    "# For VS Code\n",
    "# %pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "94c0d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch:  2.6.0+cu118\n",
      "Stable Baseline:  2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Checking for Installations\n",
    "import torch\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "print(\"Pytorch: \", torch.__version__)\n",
    "print(\"Stable Baseline: \", stable_baselines3.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fa69a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For navigating folders\n",
    "# Lets you insert custom code during training in Stable-Baselines3. It's used for tasks like saving best models, early stopping, or logging custom metrics.\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f919",
   "metadata": {},
   "source": [
    "##### Class to Automatically Save the RL Model Every Few Steps During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c97b913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseCallback: Saves the model regularly during training so model don’t lose progress if something crashes.\n",
    "class TrainAndLoggingCallback(BaseCallback):  # Custom callback extending BaseCallback for periodic model saving\n",
    "    def __init__(self, check_freq, save_path, verbose = 1):  # Initialize callback with save frequency and path\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)  # Call parent constructor with verbosity setting\n",
    "        self.check_freq = check_freq  # Set how often to save the model\n",
    "        self.save_path = save_path  # Set the directory to save models\n",
    "        \n",
    "    def _init_callback(self):  # Called at the beginning of training\n",
    "        if self.save_path is not None:  # Ensure save_path is defined\n",
    "            os.makedirs(self.save_path, exist_ok=True)  # Create save directory if it doesn't exist\n",
    "    \n",
    "    def _on_step(self):  # Called at every step during training\n",
    "        if self.n_calls % self.check_freq == 0:  # Check if current step is a checkpoint\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls)) # Constructs the full file path to save the model, inside the specified save_path directory. This enables saving multiple model versions at regular intervals during training for later evaluation.\n",
    "            self.model.save(model_path)  # Save current model to the constructed path\n",
    "        return True  # Continue training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic' # Directory for saving our trained RL Model\n",
    "LOG_DIR = './logs/log_basic' # Directory for saving the PPO Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b01b4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of our Training and Logging Callback\n",
    "# This means after every 10,000 steps of training the model, we are going to save the version of those PyTorch Weights of our RL Agent.\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7185c36",
   "metadata": {},
   "source": [
    "### Actually Training the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9078dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PPO for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Model is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(seed=0):\n",
    "    def _init():\n",
    "        env = VizDoomGym(render=False)\n",
    "        env.seed(seed)\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "env = DummyVecEnv([make_env(seed=SEED)])  # Single env wrapped in DummyVecEnv with Monitor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = PPO(\n",
    "    'CnnPolicy',\n",
    "    env,\n",
    "    tensorboard_log=LOG_DIR,\n",
    "    verbose=1,\n",
    "    learning_rate=0.0001,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    device=device,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(\"Model is on:\", model.policy.device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'CnnPolicy': Uses a convolutional neural network, used for processing image-based observations like game frames.\n",
    "# env: The environment where the agent learns and acts; must follow the Gymnasium API.\n",
    "# tensorboard_log=LOG_DIR: Specifies the path to save logs for visualizing training metrics using TensorBoard.\n",
    "# verbose=1: Enables informational output during training; helps monitor progress in the console.\n",
    "# learning_rate=0.0001: Controls how quickly the model updates its knowledge; lower values lead to more stable learning.\n",
    "# n_steps=2048: Number of environment steps to run (frames to store) before each policy update; affects training stability and memory use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005221c",
   "metadata": {},
   "source": [
    "# Note: \n",
    "### Only Run this code cell if you want to train the model. Otherwise don't. Skip to Testing directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff013a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -67.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 30       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | -63.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088392235 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.000326    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.6        |\n",
      "|    ep_rew_mean          | -20.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012660071 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.8        |\n",
      "|    ep_rew_mean          | -17.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014410733 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.2       |\n",
      "|    ep_rew_mean          | -9.97      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 366        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01248732 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 882        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | 0.00497    |\n",
      "|    value_loss           | 2.54e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.7       |\n",
      "|    ep_rew_mean          | 5.82       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 442        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01375779 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.969     |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 908        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.00295    |\n",
      "|    value_loss           | 2.68e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 16.7       |\n",
      "|    ep_rew_mean          | 6.94       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 517        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02217684 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.962     |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.58e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | 0.00538    |\n",
      "|    value_loss           | 3.61e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.8        |\n",
      "|    ep_rew_mean          | -4.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024303157 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00771     |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21          |\n",
      "|    ep_rew_mean          | -16.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018657837 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.6        |\n",
      "|    ep_rew_mean          | -8.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021636173 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00264     |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.5        |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 822         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011650002 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.00612     |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 16.9       |\n",
      "|    ep_rew_mean          | 13.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 898        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05282896 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.821     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.26e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.00957    |\n",
      "|    value_loss           | 3.21e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.94        |\n",
      "|    ep_rew_mean          | 55          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 979         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016390637 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.76       |\n",
      "|    ep_rew_mean          | 66.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 1060       |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02067208 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.818     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 695        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.0274     |\n",
      "|    value_loss           | 2.45e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.5         |\n",
      "|    ep_rew_mean          | 73.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1146        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048823282 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.000536    |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.28       |\n",
      "|    ep_rew_mean          | 75.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 26         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 1237       |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05400537 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.722     |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 320        |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.00652    |\n",
      "|    value_loss           | 789        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.84        |\n",
      "|    ep_rew_mean          | 82.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1328        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070713565 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00969     |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.96        |\n",
      "|    ep_rew_mean          | 81.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1419        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032525774 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.543      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.74        |\n",
      "|    ep_rew_mean          | 74.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1510        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038605083 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 372         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00768     |\n",
      "|    value_loss           | 377         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.63        |\n",
      "|    ep_rew_mean          | 79.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1604        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.073467776 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0033      |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.02        |\n",
      "|    ep_rew_mean          | 82.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1699        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031235723 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00606     |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.41        |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030867001 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 75.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00907     |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.39       |\n",
      "|    ep_rew_mean          | 84.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 1896       |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07223678 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.559      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.0312     |\n",
      "|    value_loss           | 90.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.39       |\n",
      "|    ep_rew_mean          | 84.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1994       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03801459 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.211     |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 39.9       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.00206    |\n",
      "|    value_loss           | 55.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.14        |\n",
      "|    ep_rew_mean          | 86.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2089        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034693513 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.201      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.0252      |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.86        |\n",
      "|    ep_rew_mean          | 82.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 2184        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013671162 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.02       |\n",
      "|    ep_rew_mean          | 86.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 2285       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04286978 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.157     |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.7         |\n",
      "|    ep_rew_mean          | 83.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 2380        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013920793 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 3.61      |\n",
      "|    ep_rew_mean          | 88.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 23        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 2478      |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2643375 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.161    |\n",
      "|    explained_variance   | 0.481     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 30.5      |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 0.00888   |\n",
      "|    value_loss           | 128       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.97        |\n",
      "|    ep_rew_mean          | 86.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 2581        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028354816 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.195      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.67        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0325      |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.36       |\n",
      "|    ep_rew_mean          | 85.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 2680       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11101916 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.156     |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.87       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.0186     |\n",
      "|    value_loss           | 56.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.13        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 2778        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024240416 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.034       |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.55       |\n",
      "|    ep_rew_mean          | 84.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 2875       |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04907889 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.162     |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.95       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.0125     |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.29       |\n",
      "|    ep_rew_mean          | 85.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 2975       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03739061 |\n",
      "|    clip_fraction        | 0.0842     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00455   |\n",
      "|    value_loss           | 38.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | 85.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 3073        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017774113 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.125      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.0175      |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.8         |\n",
      "|    ep_rew_mean          | 87.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 3173        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004766819 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.87       |\n",
      "|    ep_rew_mean          | 87.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 3276       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00990562 |\n",
      "|    clip_fraction        | 0.0638     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    value_loss           | 32         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.6         |\n",
      "|    ep_rew_mean          | 83.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 3381        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016849177 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0911     |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.27        |\n",
      "|    ep_rew_mean          | 85.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 3481        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052110408 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0934     |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.93       |\n",
      "|    ep_rew_mean          | 82.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 3573       |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07224198 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.16      |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.99       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.0352     |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.75        |\n",
      "|    ep_rew_mean          | 82.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 3672        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031659454 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.75        |\n",
      "|    ep_rew_mean          | 83.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 3769        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009580276 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0824     |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.55        |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 3870        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018258408 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.31        |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 3970        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037674762 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0962     |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.57        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00444     |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.36        |\n",
      "|    ep_rew_mean          | 84.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 4068        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027238306 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.08       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.16        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.046       |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.35        |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 4169        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049353514 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0678     |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 4269        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031070145 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.066      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.7        |\n",
      "|    ep_rew_mean          | 88.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 4369       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45932484 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.077     |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.00702    |\n",
      "|    value_loss           | 75.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.08       |\n",
      "|    ep_rew_mean          | 86.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 4468       |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04130833 |\n",
      "|    clip_fraction        | 0.0567     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0876    |\n",
      "|    explained_variance   | 0.795      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 6.81       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | 0.0152     |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.83        |\n",
      "|    ep_rew_mean          | 87.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 4565        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063203275 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.72        |\n",
      "|    ep_rew_mean          | 88.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 4665        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022750597 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.2        |\n",
      "|    ep_rew_mean          | 86.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 4764       |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03665597 |\n",
      "|    clip_fraction        | 0.081      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0901    |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.16       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.0503     |\n",
      "|    value_loss           | 5.82       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.44        |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 4861        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010702994 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0667     |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | 0.0389      |\n",
      "|    value_loss           | 9.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.35        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 4960        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019478075 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0594     |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 5058        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047851678 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.066      |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.0238      |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.48        |\n",
      "|    ep_rew_mean          | 83.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 5151        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023557832 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0544     |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.79        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.0174      |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.7         |\n",
      "|    ep_rew_mean          | 88.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 5251        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046429962 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0763     |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.00461     |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.57        |\n",
      "|    ep_rew_mean          | 88.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 5351        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029393384 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0509     |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | 86.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 5453        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012940871 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0433     |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.73        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.42        |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 5552        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021803433 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0425     |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.18        |\n",
      "|    ep_rew_mean          | 86.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 5650        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012619806 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.045      |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 0.000909    |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.83        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 5748        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011572704 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0484     |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00418     |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.96        |\n",
      "|    ep_rew_mean          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 5847        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006106371 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0378     |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00693     |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.6       |\n",
      "|    ep_rew_mean          | 83.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 22        |\n",
      "|    iterations           | 64        |\n",
      "|    time_elapsed         | 5945      |\n",
      "|    total_timesteps      | 131072    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0257441 |\n",
      "|    clip_fraction        | 0.0288    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0433   |\n",
      "|    explained_variance   | 0.946     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.12      |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | 0.00869   |\n",
      "|    value_loss           | 5.69      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.69        |\n",
      "|    ep_rew_mean          | 87.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 6045        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031976834 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0557     |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.000959    |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.72        |\n",
      "|    ep_rew_mean          | 88          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 6146        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082319364 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0461     |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.66        |\n",
      "|    ep_rew_mean          | 88.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 6249        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021220174 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0426     |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.5         |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 6350        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016795633 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0447     |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.7         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.00726     |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.89         |\n",
      "|    ep_rew_mean          | 87.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 6453         |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065932698 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0485      |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.98         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | 0.0145       |\n",
      "|    value_loss           | 9.08         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.14        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 6553        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013571562 |\n",
      "|    clip_fraction        | 0.034       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0488     |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.972       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.0214      |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.76        |\n",
      "|    ep_rew_mean          | 87.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 6655        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008894825 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0438     |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 7.85        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 6.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.54        |\n",
      "|    ep_rew_mean          | 88.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 6756        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019279215 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0392     |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.00376     |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.61        |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 6857        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027620453 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0324     |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.753       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.00882     |\n",
      "|    value_loss           | 3.77        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.96       |\n",
      "|    ep_rew_mean          | 87.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 6958       |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01782712 |\n",
      "|    clip_fraction        | 0.0379     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0353    |\n",
      "|    explained_variance   | 0.836      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.66       |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | 0.00568    |\n",
      "|    value_loss           | 22.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1ec19118740>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.learn(total_timesteps=150000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934eb11",
   "metadata": {},
   "source": [
    "# Testing the RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "167084ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Evaluate_Policy to Test the Agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342faec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model (from Disk), the total trained list. In my case the latest model present in directory is loaded\n",
    "model = PPO.load('./basic_250000')\n",
    "env = VizDoomGym(render=True) # Rendered Environment for Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5a771796",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=50) # Evaluating Mean Reward for 10 games of DOOM!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b10410b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.01899986743928"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8a91d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1: 83.2\n",
      "Total Reward for episode 2: 71.35\n",
      "Total Reward for episode 3: 95.05\n",
      "Total Reward for episode 4: 87.15\n",
      "Total Reward for episode 5: 95.05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "for episode in range(5):\n",
    "    obs = env.reset()[0]  # <-- FIX: get only the observation\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        time.sleep(0.20)\n",
    "        # print(\"Rewards: \", reward)\n",
    "        # print(\"Rewards[0]: \", reward[0])\n",
    "        total_reward += reward  # reward is a vector from DummyVecEnv\n",
    "    print(f\"Total Reward for episode {episode + 1}: {total_reward}\")\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ccccb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
